import os
from dotenv import load_dotenv, find_dotenv
import streamlit as st

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

load_dotenv(find_dotenv(), override=False)
API_KEY = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="LangChainãƒ‡ãƒ¢ - A/Bå°‚é–€å®¶", page_icon="ğŸ³", layout="centered")

if not API_KEY:
    st.error("OPENAI_API_KEY ãŒèª­ã¿è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚.env ã‚‚ã—ãã¯ st.secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

def run_llm(user_text: str, expert_key: str) -> str:
    expert_systems = {
        "A": (
            "ã‚ãªãŸã¯å’Œé£Ÿã®æ–™ç†ç ”ç©¶å®¶ã§ã™ã€‚å‡ºæ±ãƒ»ä¸‹å‘³ãƒ»ç«å…¥ã‚Œã®è¦ç‚¹ã‚’ä¸å¯§ã«èª¬æ˜ã—ã€"
            "å®¶åº­ã§å†ç¾ã—ã‚„ã™ã„ãƒ¬ã‚·ãƒ”ã‚„ã‚³ãƒ„ã‚’ã€å…·ä½“çš„ãªæ‰‹é †ç•ªå·ã¤ãã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        ),
        "B": (
            "ã‚ãªãŸã¯æ´‹é£Ÿã®æ–™ç†ç ”ç©¶å®¶ã§ã™ã€‚ã‚½ãƒ†ãƒ¼ã€ãƒ‡ã‚°ãƒ¬ãƒ¼ã‚ºã€ä¹³åŒ–ã€ã‚½ãƒ¼ã‚¹ä½œã‚Šã®è¦ç‚¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã€"
            "å®¶åº­ã§å†ç¾ã—ã‚„ã™ã„ãƒ¬ã‚·ãƒ”ã‚„ã‚³ãƒ„ã‚’ã€å…·ä½“çš„ãªæ‰‹é †ç•ªå·ã¤ãã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        ),
    }
    system_message = expert_systems.get(expert_key, expert_systems["A"])

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("human", "{input_text}"),
        ]
    )

    llm = ChatOpenAI(
        api_key=API_KEY,
        model="gpt-4o-mini",
        temperature=0.5 if expert_key == "A" else 0.8,
    )

    parser = StrOutputParser()

    chain = prompt | llm | parser
    result = chain.invoke({"input_text": user_text})
    return result.strip()

st.title("æ–™ç†å°‚é–€å®¶ã«ç›¸è«‡ã™ã‚‹ã‚¢ãƒ—ãƒª")

st.markdown(
    """
### ã‚¢ãƒ—ãƒªã®æ¦‚è¦
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸ã³ã€å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
  é¸æŠã«å¿œã˜ãŸå°‚é–€å®¶ãŒå›ç­”ã—ã¾ã™ã€‚

### æ“ä½œæ–¹æ³•
1. ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ
2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ç´ æã‚„ç›¸è«‡å†…å®¹ã‚’è¨˜å…¥
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ç”»é¢ä¸‹ã«å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
"""
)

expert_choice = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
    ["å’Œé£Ÿã®æ–™ç†å°‚é–€å®¶", "æ´‹é£Ÿã®æ–™ç†å°‚é–€å®¶"]
)

user_text = st.text_area(
    "ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆææ–™ãƒ»å¸Œæœ›ãªã©ï¼‰",
    height=120,
    placeholder="ä¾‹ï¼šé¶ã‚‚ã‚‚ã¨ç‰ã­ãã‚’ä½¿ã£ã¦ã€‚ç°¡å˜ã«ã§ãã‚‹ã‚‚ã®"
)

if st.button("é€ä¿¡", type="primary"):
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã¦ã­ã€‚")
    else:
        with st.spinner("å°‚é–€å®¶ãŒè€ƒãˆä¸­â€¦"):
            try:
                answer = run_llm(user_text, expert_choice)
                st.subheader("å›ç­”")
                st.markdown(answer)
            except Exception as e:
                st.error("ç”Ÿæˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                st.caption(f"{type(e).__name__}: {e}")
